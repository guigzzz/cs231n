{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "Conv = namedtuple('Conv', ['kernel', 'stride', 'depth'])\n",
    "DepthSepConv = namedtuple('DepthSepConv', ['kernel', 'stride', 'depth'])\n",
    "\n",
    "# _CONV_DEFS specifies the MobileNet body\n",
    "_CONV_DEFS = [\n",
    "    Conv(kernel=[3, 3], stride=2, depth=32),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=64),\n",
    "    DepthSepConv(kernel=[3, 3], stride=2, depth=128),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=128),\n",
    "    DepthSepConv(kernel=[3, 3], stride=2, depth=256),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=256),\n",
    "    DepthSepConv(kernel=[3, 3], stride=2, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=512),\n",
    "    DepthSepConv(kernel=[3, 3], stride=2, depth=1024),\n",
    "    DepthSepConv(kernel=[3, 3], stride=1, depth=1024)\n",
    "]\n",
    "\n",
    "def _reduced_kernel_size_for_small_input(input_tensor, kernel_size):\n",
    "  \"\"\"Define kernel size which is automatically reduced for small input.\n",
    "  If the shape of the input images is unknown at graph construction time this\n",
    "  function assumes that the input images are large enough.\n",
    "  Args:\n",
    "    input_tensor: input tensor of size [batch_size, height, width, channels].\n",
    "    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n",
    "  Returns:\n",
    "    a tensor with the kernel size.\n",
    "  \"\"\"\n",
    "  shape = input_tensor.get_shape().as_list()\n",
    "  if shape[1] is None or shape[2] is None:\n",
    "    kernel_size_out = kernel_size\n",
    "  else:\n",
    "    kernel_size_out = [min(shape[1], kernel_size[0]),\n",
    "                       min(shape[2], kernel_size[1])]\n",
    "  return kernel_size_out\n",
    "\n",
    "def mobilenet_v1_base(inputs,\n",
    "                      final_endpoint='Conv2d_13_pointwise',\n",
    "                      min_depth=8,\n",
    "                      depth_multiplier=1.0,\n",
    "                      conv_defs=None,\n",
    "                      output_stride=None,\n",
    "                      scope=None):\n",
    "  \"\"\"Mobilenet v1.\n",
    "  Constructs a Mobilenet v1 network from inputs to the given final endpoint.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to. It\n",
    "      can be one of ['Conv2d_0', 'Conv2d_1_pointwise', 'Conv2d_2_pointwise',\n",
    "      'Conv2d_3_pointwise', 'Conv2d_4_pointwise', 'Conv2d_5_pointwise',\n",
    "      'Conv2d_6_pointwise', 'Conv2d_7_pointwise', 'Conv2d_8_pointwise',\n",
    "      'Conv2d_9_pointwise', 'Conv2d_10_pointwise', 'Conv2d_11_pointwise',\n",
    "      'Conv2d_12_pointwise', 'Conv2d_13_pointwise'].\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n",
    "    output_stride: An integer that specifies the requested ratio of input to\n",
    "      output spatial resolution. If not None, then we invoke atrous convolution\n",
    "      if necessary to prevent the network from reducing the spatial resolution\n",
    "      of the activation maps. Allowed values are 8 (accurate fully convolutional\n",
    "      mode), 16 (fast fully convolutional mode), 32 (classification mode).\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    tensor_out: output tensor corresponding to the final_endpoint.\n",
    "    end_points: a set of activations for external use, for example summaries or\n",
    "                losses.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "                or depth_multiplier <= 0, or the target output_stride is not\n",
    "                allowed.\n",
    "  \"\"\"\n",
    "  depth = lambda d: max(int(d * depth_multiplier), min_depth)\n",
    "  end_points = {}\n",
    "\n",
    "  # Used to find thinned depths for each layer.\n",
    "  if depth_multiplier <= 0:\n",
    "    raise ValueError('depth_multiplier is not greater than zero.')\n",
    "\n",
    "  if conv_defs is None:\n",
    "    conv_defs = _CONV_DEFS\n",
    "\n",
    "  if output_stride is not None and output_stride not in [8, 16, 32]:\n",
    "    raise ValueError('Only allowed output_stride values are 8, 16, 32.')\n",
    "\n",
    "  with tf.variable_scope(scope, 'MobilenetV1', [inputs]):\n",
    "    with slim.arg_scope([slim.conv2d, slim.separable_conv2d], padding='SAME'):\n",
    "      # The current_stride variable keeps track of the output stride of the\n",
    "      # activations, i.e., the running product of convolution strides up to the\n",
    "      # current network layer. This allows us to invoke atrous convolution\n",
    "      # whenever applying the next convolution would result in the activations\n",
    "      # having output stride larger than the target output_stride.\n",
    "      current_stride = 1\n",
    "\n",
    "      # The atrous convolution rate parameter.\n",
    "      rate = 1\n",
    "\n",
    "      net = inputs\n",
    "      for i, conv_def in enumerate(conv_defs):\n",
    "        end_point_base = 'Conv2d_%d' % i\n",
    "\n",
    "        if output_stride is not None and current_stride == output_stride:\n",
    "          # If we have reached the target output_stride, then we need to employ\n",
    "          # atrous convolution with stride=1 and multiply the atrous rate by the\n",
    "          # current unit's stride for use in subsequent layers.\n",
    "          layer_stride = 1\n",
    "          layer_rate = rate\n",
    "          rate *= conv_def.stride\n",
    "        else:\n",
    "          layer_stride = conv_def.stride\n",
    "          layer_rate = 1\n",
    "          current_stride *= conv_def.stride\n",
    "\n",
    "        if isinstance(conv_def, Conv):\n",
    "          end_point = end_point_base\n",
    "          net = slim.conv2d(net, depth(conv_def.depth), conv_def.kernel,\n",
    "                            stride=conv_def.stride,\n",
    "                            normalizer_fn=slim.batch_norm,\n",
    "                            scope=end_point)\n",
    "          end_points[end_point] = net\n",
    "          if end_point == final_endpoint:\n",
    "            return net, end_points\n",
    "\n",
    "        elif isinstance(conv_def, DepthSepConv):\n",
    "          end_point = end_point_base + '_depthwise'\n",
    "\n",
    "          # By passing filters=None\n",
    "          # separable_conv2d produces only a depthwise convolution layer\n",
    "          net = slim.separable_conv2d(net, None, conv_def.kernel,\n",
    "                                      depth_multiplier=1,\n",
    "                                      stride=layer_stride,\n",
    "                                      rate=layer_rate,\n",
    "                                      normalizer_fn=slim.batch_norm,\n",
    "                                      scope=end_point)\n",
    "\n",
    "          end_points[end_point] = net\n",
    "          if end_point == final_endpoint:\n",
    "            return net, end_points\n",
    "\n",
    "          end_point = end_point_base + '_pointwise'\n",
    "\n",
    "          net = slim.conv2d(net, depth(conv_def.depth), [1, 1],\n",
    "                            stride=1,\n",
    "                            normalizer_fn=slim.batch_norm,\n",
    "                            scope=end_point)\n",
    "\n",
    "          end_points[end_point] = net\n",
    "          if end_point == final_endpoint:\n",
    "            return net, end_points\n",
    "        else:\n",
    "          raise ValueError('Unknown convolution type %s for layer %d'\n",
    "                           % (conv_def.ltype, i))\n",
    "  raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
    "\n",
    "\n",
    "def mobilenet_v1(inputs,\n",
    "                 num_classes=1000,\n",
    "                 dropout_keep_prob=0.999,\n",
    "                 is_training=True,\n",
    "                 min_depth=8,\n",
    "                 depth_multiplier=1.0,\n",
    "                 conv_defs=None,\n",
    "                 prediction_fn=tf.contrib.layers.softmax,\n",
    "                 spatial_squeeze=True,\n",
    "                 reuse=None,\n",
    "                 scope='MobilenetV1'):\n",
    "  \"\"\"Mobilenet v1 model for classification.\n",
    "  Args:\n",
    "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
    "    num_classes: number of predicted classes.\n",
    "    dropout_keep_prob: the percentage of activation values that are retained.\n",
    "    is_training: whether is training or not.\n",
    "    min_depth: Minimum depth value (number of channels) for all convolution ops.\n",
    "      Enforced when depth_multiplier < 1, and not an active constraint when\n",
    "      depth_multiplier >= 1.\n",
    "    depth_multiplier: Float multiplier for the depth (number of channels)\n",
    "      for all convolution ops. The value must be greater than zero. Typical\n",
    "      usage will be to set this value in (0, 1) to reduce the number of\n",
    "      parameters or computation cost of the model.\n",
    "    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n",
    "    prediction_fn: a function to get predictions out of logits.\n",
    "    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n",
    "        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n",
    "    reuse: whether or not the network and its variables should be reused. To be\n",
    "      able to reuse 'scope' must be given.\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    logits: the pre-softmax activations, a tensor of size\n",
    "      [batch_size, num_classes]\n",
    "    end_points: a dictionary from components of the network to the corresponding\n",
    "      activation.\n",
    "  Raises:\n",
    "    ValueError: Input rank is invalid.\n",
    "  \"\"\"\n",
    "  input_shape = inputs.get_shape().as_list()\n",
    "  if len(input_shape) != 4:\n",
    "    raise ValueError('Invalid input tensor rank, expected 4, was: %d' %\n",
    "                     len(input_shape))\n",
    "\n",
    "  with tf.variable_scope(scope, 'MobilenetV1', [inputs, num_classes],\n",
    "                         reuse=reuse) as scope:\n",
    "    with slim.arg_scope([slim.batch_norm, slim.dropout],\n",
    "                        is_training=is_training):\n",
    "      net, end_points = mobilenet_v1_base(inputs, scope=scope,\n",
    "                                          min_depth=min_depth,\n",
    "                                          depth_multiplier=depth_multiplier,\n",
    "                                          conv_defs=conv_defs)\n",
    "      with tf.variable_scope('Logits'):\n",
    "        kernel_size = _reduced_kernel_size_for_small_input(net, [7, 7])\n",
    "        net = slim.avg_pool2d(net, kernel_size, padding='VALID',\n",
    "                              scope='AvgPool_1a')\n",
    "        end_points['AvgPool_1a'] = net\n",
    "        # 1 x 1 x 1024\n",
    "        net = slim.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
    "        logits = slim.conv2d(net, num_classes, [1, 1], activation_fn=None,\n",
    "                             normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        if spatial_squeeze:\n",
    "          logits = tf.squeeze(logits, [1, 2], name='SpatialSqueeze')\n",
    "      end_points['Logits'] = logits\n",
    "      if prediction_fn:\n",
    "        end_points['Predictions'] = prediction_fn(logits, scope='Predictions')\n",
    "  return logits, end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(labels, y):    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 256\n",
    "print_every = 100\n",
    "plot_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: training loss = 2.79, train accuracy of 0.078\n",
      "Iteration 100: training loss = 2.23, train accuracy of 0.19\n",
      "Iteration 200: training loss = 2.21, train accuracy of 0.22\n",
      "Iteration 300: training loss = 1.95, train accuracy of 0.27\n",
      "Iteration 400: training loss = 1.81, train accuracy of 0.36\n",
      "Iteration 500: training loss = 1.8, train accuracy of 0.33\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()    \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#inputs,num_classes=1000,is_training=True,width_multiplier=1,scope='MobileNet'\n",
    "logits, _ = mobilenet_v1(inputs = X, num_classes=10, is_training=is_training)\n",
    "accuracy_op = get_accuracy(y, logits)\n",
    "loss_op = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, 10), logits=logits)\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-1)\n",
    "train_op = optimizer.minimize(loss = loss_op) \n",
    "\n",
    "train_indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(train_indices)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    all_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = []\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(X_train.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%X_train.shape[0]\n",
    "            idx = train_indices[start_idx:start_idx+batch_size]\n",
    "\n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: X_train[idx,:],\n",
    "                         y: y_train[idx],\n",
    "                        is_training : True}\n",
    "            # get batch size\n",
    "            actual_batch_size = y_train[idx].shape[0]\n",
    "\n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, acc, _ = session.run([loss_op, accuracy_op, train_op], feed_dict=feed_dict)\n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct.append(acc)\n",
    "\n",
    "            # print every now and then\n",
    "            if not iter_cnt % print_every:\n",
    "                print(\"Iteration {0}: training loss = {1:.3g}, train accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,acc))\n",
    "            iter_cnt += 1\n",
    "\n",
    "        epoch_train_acc = np.sum(correct)/int(math.ceil(X_train.shape[0]/batch_size))\n",
    "        epoch_train_loss = np.sum(losses)/int(math.ceil(X_train.shape[0]/batch_size))\n",
    "\n",
    "        feed_dict = {X: X_val,\n",
    "                     y: y_val,\n",
    "                    is_training: True}\n",
    "\n",
    "        epoch_val_loss, epoch_val_acc = session.run([loss_op, accuracy_op], feed_dict)\n",
    "\n",
    "        print(\"Epoch {4}, train loss = {0:.3g}, train accuracy of {1:.3g}, val loss = {2:.3g}, val acc = {3:.3g}\" \\\n",
    "              .format(epoch_train_loss, epoch_train_acc, epoch_val_loss, epoch_val_acc, e+1))\n",
    "        print()\n",
    "        \n",
    "        all_losses += losses\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        val_acc.append(epoch_val_acc)\n",
    "        \n",
    "        if plot_loss:\n",
    "            plt.plot(all_losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
