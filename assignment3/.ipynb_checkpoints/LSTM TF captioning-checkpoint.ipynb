{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from cs231n.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "train_image_idxs <class 'numpy.ndarray'> (400135,) int32\n",
      "val_captions <class 'numpy.ndarray'> (195954, 17) int32\n",
      "val_image_idxs <class 'numpy.ndarray'> (195954,) int32\n",
      "train_features <class 'numpy.ndarray'> (82783, 512) float32\n",
      "val_features <class 'numpy.ndarray'> (40504, 512) float32\n",
      "idx_to_word <class 'list'> 1004\n",
      "word_to_idx <class 'dict'> 1004\n",
      "train_urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "val_urls <class 'numpy.ndarray'> (40504,) <U63\n"
     ]
    }
   ],
   "source": [
    "data = load_coco_data()\n",
    "\n",
    "# Print out all the keys and values from the data dictionary\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(object):\n",
    "    def __init__(self, word_to_idx, input_dim=512, wordvec_dim=256,\n",
    "                 hidden_dim=512, dtype=np.float32):\n",
    "        \"\"\"\n",
    "        Construct a new CaptioningRNN instance.\n",
    "\n",
    "        Inputs:\n",
    "        - word_to_idx: A dictionary giving the vocabulary. It contains V entries,\n",
    "          and maps each string to a unique integer in the range [0, V).\n",
    "        - input_dim: Dimension D of input image feature vectors.\n",
    "        - wordvec_dim: Dimension W of word vectors.\n",
    "        - hidden_dim: Dimension H for the hidden state of the RNN.\n",
    "        - cell_type: What type of RNN to use; either 'rnn' or 'lstm'.\n",
    "        - dtype: numpy datatype to use; use float32 for training and float64 for\n",
    "          numeric gradient checking.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dtype = dtype\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "        self.params = {}\n",
    "\n",
    "        vocab_size = len(word_to_idx)\n",
    "\n",
    "        self._null = word_to_idx['<NULL>']\n",
    "        self._start = word_to_idx.get('<START>', None)\n",
    "        self._end = word_to_idx.get('<END>', None)\n",
    "\n",
    "        # Initialize word vectors\n",
    "        self.params['W_embed'] = tf.Variable(tf.random_normal((vocab_size, wordvec_dim)) / 100.0, name = 'W_embed')\n",
    "\n",
    "        # Initialize NN -> hidden state projection parameters\n",
    "        self.params['W_proj'] = tf.Variable(tf.random_normal((input_dim, hidden_dim)) / tf.sqrt(float(input_dim)), name = 'W_proj')\n",
    "        self.params['b_proj'] = tf.Variable(tf.zeros(hidden_dim), name = 'b_proj')\n",
    "\n",
    "        # Initialize output to vocab weights\n",
    "        self.params['W_vocab'] = tf.Variable(tf.random_normal((hidden_dim, vocab_size)) / tf.sqrt(float(hidden_dim)), name = 'W_vocab')\n",
    "        self.params['b_vocab'] = tf.Variable(tf.zeros(vocab_size), name = 'b_vocab')\n",
    "            \n",
    "#         self.model = tf.contrib.cudnn_rnn.CudnnLSTM(\n",
    "#             num_layers = 1,\n",
    "#             num_units = hidden_dim,\n",
    "#             input_size = input_dim\n",
    "#             )\n",
    "        self.model = tf.contrib.rnn.BasicLSTMCell(hidden_dim)\n",
    "    \n",
    "#         self.input_dim = input_dim\n",
    "#         self.wordvec_dim = wordvec_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.vocab_size = vocab_size\n",
    "            \n",
    "    def get_forward_op(self, features, captions_in):\n",
    "        W_proj, b_proj = self.params['W_proj'], self.params['b_proj']\n",
    "        # Word embedding matrix\n",
    "        W_embed = self.params['W_embed']\n",
    "        \n",
    "        # Weight and bias for the hidden-to-vocab transformation.\n",
    "        W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']\n",
    "        \n",
    "        h0 = tf.matmul(features, W_proj) + b_proj # W_proj : input x hidden\n",
    "        \n",
    "        word_embeds = tf.nn.embedding_lookup(W_embed, captions_in) # W_embed : vocab_size x wordvec_dim\n",
    "        \n",
    "        unrolled_output, _ = tf.nn.dynamic_rnn(\n",
    "            self.model, \n",
    "            inputs = word_embeds,\n",
    "            initial_state = tf.contrib.rnn.LSTMStateTuple( h0, tf.zeros_like(h0) ) # https://github.com/tensorflow/tensorflow/issues/3860\n",
    "        )\n",
    "        \n",
    "        T, D = unrolled_output.get_shape().as_list()[1:]\n",
    "        M = b_vocab.get_shape().as_list()[0]\n",
    "        shape = tf.shape(unrolled_output)\n",
    "        dim = tf.reduce_prod(shape[:2])\n",
    "\n",
    "        logits = tf.reshape(tf.matmul(\n",
    "            tf.reshape(unrolled_output, [dim, D]),\n",
    "            W_vocab\n",
    "        ), [shape[0], T, M]) + b_vocab\n",
    "        \n",
    "        return logits        \n",
    "    \n",
    "    def get_train_and_loss_ops(self, x, y, mask):\n",
    "        shape = tf.shape(x)\n",
    "        M = x.get_shape().as_list()[2]\n",
    "        dim = tf.reduce_prod(shape[:2])\n",
    "\n",
    "        x_flat = tf.reshape(x, [dim, M])\n",
    "        y_flat = tf.reshape(y, [dim])\n",
    "        mask_flat = tf.reshape(mask, [dim])\n",
    "\n",
    "        probs = tf.exp(x_flat - tf.reduce_max(x_flat, axis=1, keep_dims=True))\n",
    "        probs /= tf.reduce_sum(probs, axis=1, keep_dims=True)\n",
    "        \n",
    "        # https://github.com/tensorflow/tensorflow/issues/418\n",
    "        sel = tf.log(tf.gather(tf.reshape(probs, [-1]), tf.range(dim) * tf.shape(probs)[1] + y_flat))\n",
    "        \n",
    "        loss = -tf.reduce_sum(tf.cast(mask_flat, tf.float32) * sel) / tf.cast(shape[0], tf.float32)\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(5e-3).minimize(loss)\n",
    "\n",
    "        return train_op, loss\n",
    "    \n",
    "    def get_infer_op(self, features, max_length=30):\n",
    "        N = tf.shape(features)[0]\n",
    "\n",
    "        # Unpack parameters\n",
    "        W_proj, b_proj = self.params['W_proj'], self.params['b_proj']\n",
    "        W_embed = self.params['W_embed']\n",
    "        W_vocab, b_vocab = self.params['W_vocab'], self.params['b_vocab']\n",
    "        \n",
    "        h0 = tf.matmul(features, W_proj) + b_proj\n",
    "        \n",
    "        x = tf.cast(tf.ones(shape = (N, )) * self._start, tf.int32)\n",
    "        c = tf.zeros_like(h0)\n",
    "                \n",
    "        state = h0, c\n",
    "        captions = []\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            output, state = self.model( tf.nn.embedding_lookup(W_embed, x), state )\n",
    "            \n",
    "            x = tf.argmax(\n",
    "                tf.matmul(output, W_vocab) + b_vocab, \n",
    "                axis = 1\n",
    "            )\n",
    "            captions.append(x)\n",
    "            \n",
    "        return np.asarray(captions).T      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "val_batch_size = 10000\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e2cf41532fe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[0mmask_ph\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 }\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mval_loss_all\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation loss {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss_all\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_val_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rameg\\miniconda2\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "small_lstm_model = LSTM(\n",
    "          word_to_idx=data['word_to_idx'],\n",
    "          input_dim=data['train_features'].shape[1],\n",
    "          hidden_dim=512,\n",
    "          wordvec_dim=256,\n",
    "          dtype=np.float32,\n",
    "        )\n",
    "\n",
    "num_train = data['train_captions'].shape[0]\n",
    "iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch\n",
    "\n",
    "num_val = data['val_captions'].shape[0]\n",
    "num_val_batches = max(num_val // val_batch_size, 1)\n",
    "\n",
    "x_in = tf.placeholder(tf.float32, shape = (None, data['train_features'].shape[1]), name = 'x_in')\n",
    "captions_in = tf.placeholder(tf.int32, shape = (None, data['train_captions'].shape[1] - 1), name = 'cap_in')\n",
    "captions_out = tf.placeholder(tf.int32, shape = (None, data['train_captions'].shape[1] - 1), name = 'cap_out')\n",
    "mask_ph = tf.placeholder(tf.bool, shape = captions_out.shape, name = 'mask_ph')\n",
    "\n",
    "logits = small_lstm_model.get_forward_op(x_in, captions_in)\n",
    "train_op, loss_op = small_lstm_model.get_train_and_loss_ops(logits, captions_out, mask_ph)\n",
    "\n",
    "infer_op = small_lstm_model.get_infer_op(x_in)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    file_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for t in range(num_iterations):\n",
    "        \n",
    "        if not t % int(iterations_per_epoch / 10) and t:\n",
    "            print('epoch {}, train loss {}'.format(int(t / iterations_per_epoch), loss))\n",
    "            \n",
    "        if not t % iterations_per_epoch:\n",
    "            # compute validation loss at end of epoch\n",
    "            val_loss_all = 0\n",
    "            for i in range(num_val_batches):\n",
    "                \n",
    "                idxs = range(i * val_batch_size, (i + 1) * val_batch_size)\n",
    "                captions = data['val_captions'][idxs]\n",
    "                image_idxs = data['val_image_idxs'][idxs]\n",
    "                features = data['val_features'][image_idxs]\n",
    "\n",
    "                c_in = captions[:, :-1]\n",
    "                c_out = captions[:, 1:]\n",
    "                mask = (c_out != small_lstm_model._null)\n",
    "\n",
    "                feed_dict = {\n",
    "                    x_in : features,\n",
    "                    captions_in : c_in,\n",
    "                    captions_out : c_out,\n",
    "                    mask_ph : mask\n",
    "                }\n",
    "                val_loss_all += sess.run(loss_op, feed_dict=feed_dict)\n",
    "                \n",
    "            print('validation loss {}'.format(val_loss_all / num_val_batches))\n",
    "            save_path = saver.save(sess, \"models/caption_model_epoch\", global_step = int(t / iterations_per_epoch))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            print()\n",
    "\n",
    "        captions, features, urls = sample_coco_minibatch(data,\n",
    "                      batch_size=batch_size,\n",
    "                      split='train')\n",
    "        \n",
    "        c_in = captions[:, :-1]\n",
    "        c_out = captions[:, 1:]\n",
    "        mask = (c_out != small_lstm_model._null)\n",
    "        \n",
    "        feed_dict = {\n",
    "            x_in : features,\n",
    "            captions_in : c_in,\n",
    "            captions_out : c_out,\n",
    "            mask_ph : mask\n",
    "        }\n",
    "        loss, _ = sess.run([loss_op, train_op], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/caption_model_epoch_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/caption_model_epoch_1.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-6800e114a4dc>:11: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-6800e114a4dc>:11: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = \"caption_model_epoch_1\"\n",
    "\n",
    "p = \"models/{}.ckpt\".format(model)\n",
    "\n",
    "saver = tf.train.import_meta_graph(p + \".meta\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, p)\n",
    "    \n",
    "    [m for m in tf.globql_variables()]\n",
    "#     [print(m.values()) for m in ops]\n",
    "    \n",
    "#     for split in ['train', 'val']:\n",
    "#         minibatch = sample_coco_minibatch(data, split=split, batch_size=2)\n",
    "#         gt_captions, features, urls = minibatch\n",
    "#         gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "#         sample_captions = sess.run(infer_op, feed_dict={x_in: features})\n",
    "#         sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "#         for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "#             plt.imshow(image_from_url(url))\n",
    "#             plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "#             plt.axis('off')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
